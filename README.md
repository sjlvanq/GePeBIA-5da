# GePeBIA: Collaborative Multi-Agent System for Small Popular and Community Libraries (Capstone Project)

## üåü Project Overview: A Level 3 Collaborative Architecture



This project implements the design principles of a **Level 3: Collaborative Multi-Agent System** [4, p. 17], which moves beyond a monolithic design toward a **"team of specialists"** working in concert [4, p. 17; 4, p. 16]. The system's robustness and scalability are achieved through a clear **division of labor** [4, p. 17].

The architecture follows the **Core Agent Anatomy** [4, p. 19]: the reasoning Model (Brain), external Tools (Hands), and the Orchestration Layer [4, p. 19; 4, p. 20]:

| Agent | Role in the System | Core Architectural Concept | Function & Capability |
| :--- | :--- | :--- | :--- |
| **Iris** | **Orchestrator / User Experience (UX)** | **Orchestration Layer** [4, p. 22] | Manages the primary conversational flow and maintains the immediate **Session** history [3, p. 6]. |
| **Alec** | **Logistics and Inventory Specialist** | **Tools** (Function Calling) [4, p. 20; 2, p. 10] | Executes deterministic business logic, such as checking material availability and calculating loan terms. |
| **Gina** | **User Profile Manager** | **Memory** (Long-Term Persistence) [3, p. 6] | Handles multi-step user registration and manages persistent user profiles and preferences [3, p. 38]. |

## ü§ù Interoperability and Protocols

The system's collaboration relies on standardized mechanisms for communication and tool integration, adhering to AgentOps discipline [4, p. 27]:

### 1. Agent2Agent (A2A) Communication

The integration of `Alec` and `Gina` as specialized services consumed by `Iris` is achieved using the **Agent2Agent (A2A) Protocol** [5, p. 26; 5, p. 27].

*   **Decoupling:** A2A allows these specialized agents to run as independent services (simulating cross-team or cross-organization integration) [5, p. 27; 5, p. 26].
*   **Agent-as-a-Tool:** `Iris` integrates the remote agents by treating them as callable tools via the `RemoteA2aAgent` class [2, p. 13].

### 2. Structured Tool Design

The reliability of the system is improved by rigorous constraints on tool output and messaging:

*   **Design for Concise Output:** Tools must return small, structured JSON objects rather than large text blocks [2, p. 19]. This best practice prevents **Context Window Bloat**, which degrades the model's reasoning quality, increases latency, and raises token costs [2, p. 19].
*   **Describe Actions, Not Implementations:** The orchestrator's instructions must prompt the model on *what* needs to be accomplished (e.g., "Check availability") instead of specifying *how* to call the underlying tool implementation [2, p. 17; 2, p. 18].

## üõ°Ô∏è Quality, Observability, and Safety

The system is engineered for trustworthiness, operating under the principle that **Agent quality is an architectural pillar, not a final testing phase** [1, p. 46; 4, p. 6].

### 1. The Trajectory is the Truth

The specialist agents (`Alec`, `Gina`) are fundamentally constrained to enforce predictable behavior: they **MUST ALWAYS** call one tool and **MUST ONLY** return the exact, unmodified JSON output generated by that tool.

*   This rule implements the concept that **The Trajectory is the Truth** [1, p. 46; 1, p. 6]. Since the LLM's logic is non-deterministic [1, p. 11], the evaluation must assess the agent's entire decision-making process [1, p. 19; 1, p. 16].
*   This design makes the system **evaluatable-by-design** [1, p. 46], facilitating **Trajectory Evaluation** (the "Glass Box" approach) to audit reasoning, tool use, and robustness [1, p. 19; 4, p. 29].

### 2. Observability Foundation

Observability provides the essential technical foundation for judging the agent's complex process [1, p. 6; 1, p. 31].

*   **Pillars of Observability:** The practice is built on **Logs** (atomic event records or the agent's diary) [1, p. 32; 1, p. 33], **Traces** (the narrative thread linking events to show cause and effect) [1, p. 32; 1, p. 36], and **Metrics** (the aggregated health report) [1, p. 32; 1, p. 38].
*   **Tracing** is indispensable for answering "Why?" when a system fails, by visually inspecting the entire execution path, including model and tool calls [1, p. 36; 4, p. 30].

### 3. Context, Memory, and HITL Safety

*   **Memory Isolation:** The system utilizes **Memory** for long-term knowledge (user profiles) [3, p. 6], which is defined as being **highly isolated per-user** [3, p. 31] to prevent data leakage and ensure privacy [3, p. 69].
*   **Human-in-the-Loop (HITL):** The **Golden Rule of Registration** in `Iris` enforces a mandatory confirmation step (`wait_for_user_confirmation`) before initiating a sensitive action like profile creation [203; 204]. This process integrates **Human-in-the-Loop (HITL) judgment** [1, p. 26; 1, p. 46] to anchor the system's safety and alignment with governance policies [1, p. 41].

***

## üìù Bibliography

1. Meltem Subasioglu, Turan Bulmus, and Wafae Bakkali, *Agent Quality* (Google, November 2025).
2. Mike Styer, Kanchana Patlolla, Madhuranjan Mohan, and Sal Diaz, *Agent Tools & Interoperability with Model Context Protocol (MCP)* (Google, November 2025).
3. Kimberly Milam and Antonio Gulli, *Context Engineering: Sessions, Memory* (Google, November 2025).
4. Alan Blount, Antonio Gulli, Shubham Saboo, Michael Zimmermann, and Vladimir Vuskovic, *Introduction to Agents* (Google, November 2025).
5. Sokratis Kartakis, Gabriela Hernandez Larios, Ran Li, Elia Secchi, and Huang Xia, *Prototype to Production* (Google, November 2025).
